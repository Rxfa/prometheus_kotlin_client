\chapter{Evaluation and Limitations} \label{cap:evaluation}

\section{Functional Validation}

The Kotlin Prometheus client was functionally validated against the \textit{OpenMetrics} specification~\cite{openmetrics-spec}, ensuring compliance with required formatting rules, metadata emission, and semantic conventions.

To validate correctness, unit tests were written to verify:
\begin{itemize}
  \item Label handling and metric uniqueness.
  \item Output formatting according to OpenMetrics text exposition format.
  \item Correct behavior of metric operations (\texttt{inc}, \texttt{get}, \texttt{set}) across gauges, counters, histograms, and summaries.
  \item Accurate quantile configuration and observation bucketing for summaries and histograms.
  \item Safe concurrent access using coroutines and \texttt{atomicfu} primitives.
\end{itemize}

Support for histograms includes both linear and exponential bucket configuration. Summary metrics were validated for configurable quantile tracking and tolerances. The client was successfully scraped using a Prometheus server, confirming its compatibility with external collectors and exporters.

\section{Performance Considerations}

The Kotlin client prioritizes coroutine-friendly concurrency and safe metric mutation over raw throughput. As shown in benchmarking (see Subsection 5.5), read-heavy operations (\texttt{get}) perform exceptionally well and sometimes surpass the Java client in throughput.

Write-heavy operations such as \texttt{inc()}, \texttt{set()}, and \texttt{observe()} demonstrate slightly lower performance due to coroutine scheduling and atomic synchronization overhead. Histograms and summaries involve more complex logic (e.g., bucketing, rank approximation), which adds some cost to observation recording. However, the performance remains acceptable and predictable under load.

Despite this overhead, the client maintains stable performance under high concurrency thanks to:
\begin{itemize}
  \item Non-blocking metric access patterns.
  \item Scoped coroutine isolation for metric operations.
  \item Use of lock-free atomic primitives.
\end{itemize}

\section{Comparison with Other Clients}

When compared to the official Java Prometheus client:
\begin{itemize}
  \item The Kotlin client has a more idiomatic API tailored to Kotlin, with extension functions, lambdas, and DSL-style builders.
  \item Coroutine support enables suspendable metric operations and better alignment with modern Kotlin concurrency models.
  \item Histograms and summaries follow a simpler configuration model while remaining fully compliant with OpenMetrics.
  \item Mutation operations are slightly slower due to Kotlin's atomic wrappers instead of Java's \texttt{LongAdder}.
\end{itemize}

The inclusion of histogram and summary support brings metric coverage on par with the Java client, while preserving the Kotlin-first design philosophy. The implementation was validated against expected output structures and snapshot comparisons with Java-based benchmarks.

\section{Known Limitations}

While the Kotlin Prometheus client provides robust core features and coroutine support, some limitations remain:
\begin{itemize}
  \item \textbf{Limited metric types:} The client currently supports only core metric types—\texttt{counter}, \texttt{gauge}, \texttt{histogram}, and \texttt{summary}. More specialized metrics such as \texttt{info}, \texttt{state\_set}, or \texttt{enum} are not implemented.
  \item \textbf{No use of \texttt{LongAdder}:} The client avoids using JVM-specific classes like \texttt{LongAdder}, which offer superior write throughput in high-concurrency environments. Instead, it relies on portable atomic primitives to ensure coroutine safety, at the cost of some raw performance.
  \item \textbf{No PushGateway support:} Push-based metric delivery to Prometheus (e.g., via PushGateway) is not currently supported.
\end{itemize}

Future enhancements could address these limitations by:
\begin{itemize}
  \item Adding support for PushGateway integration.
  \item Extending metric coverage to include specialized types such as \texttt{info} and \texttt{state\_set}.
  \item Exploring conditional use of \texttt{LongAdder} via Java interop for high-performance counters.  \item Supporting dynamic histogram configuration.
\end{itemize}


\section{Benchmarks}

To validate the performance and runtime characteristics of our Kotlin-native Prometheus library, we conducted comparative benchmarks against the official Java Prometheus client. These benchmarks were designed to simulate real-world usage patterns involving high-throughput counter operations, as these are among the most common metrics in production systems.

To simulate asynchronous environments, both clients used a shared \texttt{Channel<Unit>} that dispatches increment signals to a coroutine-based background consumer. This setup closely mirrors usage in high-concurrency environments like HTTP servers or job schedulers.

\subsection*{Benchmark Configuration}
\begin{itemize}
    \item \textbf{Scope}: \texttt{Thread} (isolated state per thread)
    \item \textbf{Benchmark Mode}: \texttt{Throughput}
    \item \textbf{Time Unit}: \texttt{Milliseconds}
    \item \textbf{Channel Buffer}: Size 1024 with \texttt{BufferOverflow.DROP\_OLDEST}
\end{itemize}

\subsection*{Client Implementations}

\textbf{Java Client}: Used the official Prometheus Java library (\texttt{io.prometheus.client.Counter}). Metrics were created and registered globally with a background coroutine processing increment requests.

\textbf{Kotlin Client}: Used our own DSL-based Kotlin implementation (\texttt{io.github.rxfa.prometheus.core.Counter}). The setup mirrors the Java version, including coroutine usage and buffering strategy.

\subsection*{Results Overview}

While exact figures vary depending on runtime conditions, our benchmarks consistently show that:
\begin{itemize}
    \item The Kotlin client offers comparable throughput for each operation, with minimal performance overhead despite its idiomatic and coroutine-centric architecture.
    \item In latency-sensitive paths, the Kotlin client maintains competitive performance by minimizing locking and leveraging Kotlin’s structured concurrency and non-blocking primitives.
\end{itemize}


\subsection*{Benchmark Results}

We executed three separate benchmark trials to ensure consistency and statistical significance. The operations tested included counter increments and reads, gauge mutations and reads, histogram observations, and summary recording. The results below are in \texttt{ops/ms} (operations per millisecond), using JMH's \texttt{Throughput} mode.

\subsubsection*{Performance Summary}

\begin{itemize}
    \item \textbf{Counter Operations}: Our Kotlin implementation achieved higher read throughput (e.g., $\sim$930K ops/ms) and comparable or slightly better increment rates than the Java client across all runs.
    \item \textbf{Gauge Operations}: Kotlin gauges showed excellent performance in both reads and writes. Notably, Kotlin achieved higher throughput in \texttt{getGauge} operations in every trial.
    \item \textbf{Histogram Observations}: Performance was on par in two trials, with Kotlin trailing slightly in one. Variations here are likely due to timing jitter or GC noise.
    \item \textbf{Summary Observations}: The Kotlin client consistently outperformed the Java client, with improvements of 25–40\% in throughput across all benchmark runs.
\end{itemize}

\subsubsection*{Sample Benchmark Results}

\begin{center}
\begin{tabular}{lrrrr}
\toprule
\textbf{Benchmark} & \textbf{Java} & \textbf{Kotlin} & \textbf{Diff} & \textbf{Faster?} \\
\midrule
\texttt{getCounterValue}        & 784,929 & 930,915 & +18.6\% & Kotlin \\
\texttt{incrementCounter}       & 3,582   & 3,700   & +3.3\%  & Kotlin \\
\texttt{getGauge}               & 789,824 & 931,873 & +18.0\% & Kotlin \\
\texttt{setGauge}               & 3,252   & 3,496   & +7.5\%  & Kotlin \\
\texttt{observeHistogram}       & 3,497   & 3,486   & -0.3\%  & Tie \\
\texttt{observeSummary}         & 7,145   & 9,615   & +34.5\% & Kotlin \\
\bottomrule
\end{tabular}
\end{center}

\subsubsection*{Conclusion}

The benchmark results demonstrate that our Kotlin Prometheus library is not only idiomatic and ergonomic but also competitive with — and in many cases superior to — the established Java client in terms of throughput.

Key takeaways:
\begin{itemize}
    \item The coroutine-based design, combined with channel-based batching, enables efficient metric updates under load.
    \item Gauge and summary metrics show particular strength in the Kotlin implementation, benefitting from optimized internal structures and non-blocking access.
    \item Despite being written entirely in Kotlin and favoring safety and expressiveness, our implementation does not sacrifice performance.
\end{itemize}

These results validate our design choice to build a native Kotlin client from the ground up, ensuring that developers targeting the Kotlin ecosystem benefit from both performance and a clean, idiomatic API.



\subsection*{Takeaways}

The results demonstrate that a fully idiomatic Kotlin Prometheus client can achieve parity with the mature Java implementation in common operational scenarios, while offering a significantly more expressive and safe API surface for Kotlin developers.

This validates our architectural decisions around coroutine integration, label-safe design, and type-safe builders, and provides confidence that our library is suitable for production monitoring workloads in modern Kotlin services.



\section{Ktor Integration}

To demonstrate the flexibility and extensibility of the Kotlin Prometheus client, a dedicated integration module was developed for the \texttt{Ktor} server framework. This integration allows seamless instrumentation of HTTP metrics and provides a standardized endpoint for Prometheus scraping.

\subsection*{Instrumentation Overview}
The integration exposes a function \texttt{installPrometheusMetrics}, which registers the relevant collectors to a provided \texttt{CollectorRegistry} (defaulting to a new one) and wires up Ktor's \texttt{ApplicationCallPipeline} and \texttt{StatusPages} to intercept and record:

\begin{itemize}
  \item Total HTTP requests (\texttt{http\_requests\_total}), labeled by method and normalized path.
  \item Total HTTP error responses (\texttt{http\_requests\_errors\_total}), labeled by method, path, and status code.
  \item Total exceptions during request handling (\texttt{http\_exceptions\_total}), labeled by method, path, and exception type.
  \item Duration of requests captured through histogram (\texttt{http\_request\_duration\_seconds\_histogram}), summary, and custom bucket metrics.
  \item Current number of users via a gauge (\texttt{http\_current\_users}).
\end{itemize}

Each metric includes label-based differentiation to allow fine-grained analysis of system behavior and performance.

\subsection*{Metrics Endpoint Exposure}
The integration also offers optional HTTP endpoint exposure via a configurable path (defaulting to \texttt{/metrics}). When enabled, this endpoint responds with metrics encoded in the OpenMetrics text exposition format. The developer can optionally include timestamps in the output by adjusting the integration configuration.

\subsection*{Traffic Simulation and Example Application}
An example Ktor application demonstrates practical usage of the metrics system. It defines various endpoints (e.g., \texttt{/}, \texttt{/search}, \texttt{/orders}) and simulates randomized traffic and error conditions to showcase the client's observability capabilities. The application uses Ktor's lifecycle hooks to launch a coroutine that generates synthetic HTTP requests at runtime, mimicking realistic load patterns. Errors and exceptions are injected stochastically to validate metrics tracking under adverse conditions.

\subsection*{Normalization Strategy}
To prevent label cardinality explosion, the integration applies path normalization using regular expressions. Numeric segments and UUIDs are replaced with a placeholder (\texttt{\{param\}}), ensuring consistent labeling for variable endpoints such as \texttt{/users/1234} or \texttt{/orders/uuid}.

\subsection*{Benefits}
This integration highlights the following benefits:
\begin{itemize}
  \item Minimal developer effort to enable metrics.
  \item Full coroutine support and non-blocking observation.
  \item Realistic and structured observability of HTTP applications.
  \item Alignment with Prometheus best practices for metric naming and label usage.
\end{itemize}

Future enhancements may include push gateway integration or dynamic configuration via a DSL to extend support for additional deployment models.

